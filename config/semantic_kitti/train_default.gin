include "./config/default.gin"

# Constants
in_channels = 4
out_channels = 19

# Data module
SemanticKITTIDataModule.data_root = "./dataset/s-kitti/sequences" # you need to modify this according to your data.
SemanticKITTIDataModule.train_batch_size = 24
SemanticKITTIDataModule.val_batch_size = 12
SemanticKITTIDataModule.train_num_workers = 24
SemanticKITTIDataModule.val_num_workers = 12
SemanticKITTIDataModule.collation_type = "collate_minkowski"

# Filtering (reduce the number of input data points)
SemanticKITTIDataModule.num_points = 10000 # TODO change in need, range from 10000 to 150000

# Augmentation
SemanticKITTIDataModule.voxel_size = 0.02

# Pytorch lightning module
LitSegmentationModuleBase.num_classes = %out_channels
LitSegmentationModuleBase.lr = 0.01
LitSegmentationModuleBase.momentum = 0.9
LitSegmentationModuleBase.weight_decay = 1e-4
LitSegmentationModuleBase.warmup_steps_ratio = 0.1
LitSegmentationModuleBase.best_metric_type = "maximize"

# Training
train.data_module_name = "SemanticKITTIDataModule"
train.gpus = 1
train.log_every_n_steps = 10
train.check_val_every_n_epoch = 10
train.refresh_rate_per_second = 1
train.best_metric = "val_mIoU"
train.max_epoch = 100
train.max_step = 100000
train.save_path = "logs_semantic_kitti"

# Logging
logged_hparams.keys = [
    "train.model_name",
    "train.data_module_name",
    "SemanticKITTIDataModule.train_batch_size",
    "SemanticKITTIDataModule.val_batch_size",
    "SemanticKITTIDataModule.train_num_workers",
    "SemanticKITTIDataModule.val_num_workers",
    "LitSegmentationModuleBase.lr",
    "LitSegmentationModuleBase.momentum",
    "LitSegmentationModuleBase.weight_decay",
    "LitSegmentationModuleBase.warmup_steps_ratio",
    "train.max_step",
    "train.gpus",

]

# override
train.project_name = "FastPointTransformer-SEMANTIC-KITTI"
